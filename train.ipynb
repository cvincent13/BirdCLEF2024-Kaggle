{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cedric/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import IPython.display as ipd\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics.classification import MulticlassAccuracy, MultilabelAccuracy\n",
    "import audiomentations\n",
    "from torch.utils.data import default_collate\n",
    "from torchvision.transforms import v2\n",
    "import timm\n",
    "\n",
    "from src.audio_utils import play_audio, plot_specgram, plot_waveform\n",
    "from src.data import AudioDataset, FrequencyMaskingAug, TimeMaskingAug\n",
    "from src.data_utils import get_metadata, get_fold, get_metadata_from_csv\n",
    "from src.train_utils import FocalLoss, BCEFocal2WayLoss, get_cosine_schedule_with_warmup, wandb_init\n",
    "from src.models import BasicClassifier, GeMClassifier, SEDClassifier\n",
    "from src.utils import score_np, roc_auc\n",
    "\n",
    "import ast\n",
    "import wandb\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    duration = 10\n",
    "    sample_rate = 32000\n",
    "    target_length = 384\n",
    "    n_mels = 128\n",
    "    n_fft = 2028\n",
    "    window = 2028\n",
    "    audio_len = duration*sample_rate\n",
    "    hop_length = audio_len // (target_length-1)\n",
    "    fmin = 20\n",
    "    fmax = 16000\n",
    "    top_db = 80\n",
    "\n",
    "    n_classes = 182\n",
    "    batch_size = 24\n",
    "    Model = SEDClassifier\n",
    "    model_name = 'eca_nfnet_l0'\n",
    "    n_folds = 5\n",
    "    upsample_thr = 50\n",
    "    use_class_weights = False   # Test\n",
    "\n",
    "    standardize = False\n",
    "    dataset_mean = [-16.8828]\n",
    "    dataset_std = [12.4019]\n",
    "\n",
    "    data_aug = True     # Test     \n",
    "    cutmix_mixup = True     # Test\n",
    "    loss = 'bce'    # Test ('crossentropy', 'bce')\n",
    "    secondary_labels_weight = 0.3   # Test (0)\n",
    "    use_focal = False    # Test (only with bce)\n",
    "    use_2wayfocal = True\n",
    "    focal_gamma = 2\n",
    "    focal_lambda = 1\n",
    "    label_smoothing = 0.05  # Only with crossentropy\n",
    "\n",
    "    num_epochs = 10\n",
    "    warmup_epochs = 0.5\n",
    "    lr = 1e-3\n",
    "    start_lr = 0.01 # relative to lr\n",
    "    final_lr = 0.01\n",
    "    weight_decay = 0.0001\n",
    "    max_grad_norm = 10\n",
    "\n",
    "    wandb = True\n",
    "    competition   = 'birdclef-2024' \n",
    "    _wandb_kernel = 'cvincent13'\n",
    "    date = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    run_name = f\"{date}_fold-{0}_dim-{n_mels}x{target_length}_model-{model_name}\"\n",
    "    wandb_group = 'FirstTests'\n",
    "\n",
    "    base_dir = ''\n",
    "\n",
    "#metadata = get_metadata(Config.n_folds)\n",
    "metadata = get_metadata_from_csv('metadata.csv', 'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Train: 22045, 182 classes | Num Valid: 4892, 182 classes\n"
     ]
    }
   ],
   "source": [
    "fold = 0\n",
    "train_df, valid_df, class_weights = get_fold(metadata, fold, up_thr=Config.upsample_thr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data transforms and augmentations\n",
    "waveform_transforms = audiomentations.Compose([\n",
    "    audiomentations.Shift(min_shift=-0.5, max_shift=0.5, p=0.5),\n",
    "    audiomentations.SevenBandParametricEQ(min_gain_db=-12., max_gain_db=12., p=0.5),\n",
    "    audiomentations.AirAbsorption(min_temperature=10, max_temperature=20, min_humidity=30, max_humidity=90,\n",
    "                                  min_distance=10, max_distance=100, p=1.), \n",
    "\n",
    "    audiomentations.OneOf([\n",
    "        audiomentations.Gain(min_gain_db=-6., max_gain_db=6., p=1),  # How to handle waveforms out of [-1, 1] ? dont see the issue\n",
    "        audiomentations.GainTransition(min_gain_db=-12., max_gain_db=3., p=1)\n",
    "    ], p=1.),\n",
    "\n",
    "    audiomentations.OneOf([\n",
    "        audiomentations.AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=1.),\n",
    "        audiomentations.AddGaussianSNR(min_snr_db=5., max_snr_db=40., p=1.),\n",
    "        audiomentations.AddColorNoise(min_snr_db=5., max_snr_db=40., min_f_decay=-3.01, max_f_decay=-3.01, p=1.)\n",
    "    ], p=1.),\n",
    "\n",
    "    #audiomentations.AddShortNoises(sounds_path=unlabeled_dir, min_snr_db=3., max_snr_db=30., \n",
    "    #                           noise_rms='relative_to_whole_input',\n",
    "    #                           min_time_between_sounds=2., max_time_between_sounds=8., \n",
    "    #                           noise_transform=audiomentations.PolarityInversion(), p=0.5),\n",
    "    #audiomentations.AddBackgroundNoise(sounds_path=unlabeled_dir, min_snr_db=3., max_snr_db=30., \n",
    "    #                               noise_transform=audiomentations.PolarityInversion(), p=0.5),\n",
    "                                   \n",
    "    audiomentations.LowPassFilter(min_cutoff_freq=750., max_cutoff_freq=7500., min_rolloff=12, max_rolloff=24, p=0.8),\n",
    "    audiomentations.PitchShift(min_semitones=-2.5, max_semitones=2.5, p=0.3)\n",
    "])\n",
    "\n",
    "spec_transforms = nn.Sequential(\n",
    "    FrequencyMaskingAug(0.3, 0.1, Config.n_mels, n_masks=3, mask_mode='mean'),\n",
    "    TimeMaskingAug(0.3, 0.1, Config.target_length, n_masks=3, mask_mode='mean'),\n",
    ")\n",
    "\n",
    "\n",
    "waveform_transforms=None if not Config.data_aug else waveform_transforms\n",
    "spec_transforms=None if not Config.data_aug else spec_transforms\n",
    "\n",
    "\n",
    "train_dataset = AudioDataset(\n",
    "    train_df, \n",
    "    n_classes=Config.n_classes,\n",
    "    duration=Config.duration,\n",
    "    sample_rate=Config.sample_rate,\n",
    "    target_length=Config.target_length,\n",
    "    n_mels=Config.n_mels,\n",
    "    n_fft=Config.n_fft,\n",
    "    window=Config.window,\n",
    "    hop_length=Config.hop_length,\n",
    "    fmin=Config.fmin,\n",
    "    fmax=Config.fmax,\n",
    "    top_db=Config.top_db,\n",
    "    waveform_transforms=waveform_transforms,\n",
    "    spec_transforms=spec_transforms,\n",
    "    standardize=Config.standardize,\n",
    "    mean=Config.dataset_mean,\n",
    "    std=Config.dataset_std,\n",
    "    loss=Config.loss,\n",
    "    secondary_labels_weight=Config.secondary_labels_weight\n",
    "    )\n",
    "val_dataset = AudioDataset(\n",
    "    valid_df, \n",
    "    n_classes=Config.n_classes,\n",
    "    duration=Config.duration,\n",
    "    sample_rate=Config.sample_rate,\n",
    "    target_length=Config.target_length,\n",
    "    n_mels=Config.n_mels,\n",
    "    n_fft=Config.n_fft,\n",
    "    window=Config.window,\n",
    "    hop_length=Config.hop_length,\n",
    "    fmin=Config.fmin,\n",
    "    fmax=Config.fmax,\n",
    "    top_db=Config.top_db,\n",
    "    waveform_transforms=None,\n",
    "    spec_transforms=None,\n",
    "    standardize=Config.standardize,\n",
    "    mean=Config.dataset_mean,\n",
    "    std=Config.dataset_std,\n",
    "    loss=Config.loss,\n",
    "    secondary_labels_weight=Config.secondary_labels_weight\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutmix_or_mixup = v2.RandomApply([\n",
    "    v2.RandomChoice([\n",
    "        v2.CutMix(num_classes=Config.n_classes, alpha=0.5, one_hot_labels=Config.loss=='bce'),\n",
    "        v2.MixUp(num_classes=Config.n_classes, alpha=0.5, one_hot_labels=Config.loss=='bce')\n",
    "    ], p=[0.65, 0.35])\n",
    "], p=0.7)\n",
    "\n",
    "\n",
    "def mix_collate_fn(batch):\n",
    "    return cutmix_or_mixup(*default_collate(batch))\n",
    "\n",
    "collate_fn = mix_collate_fn if Config.cutmix_mixup else None\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=Config.batch_size, shuffle=True, num_workers=4, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=Config.batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "\n",
    "model = Config.Model(Config.n_classes, Config.model_name, n_mels=Config.n_mels).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), weight_decay=Config.weight_decay, lr=Config.lr)\n",
    "spe = len(train_loader)\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=spe*Config.warmup_epochs, num_training_steps=spe*Config.num_epochs, \n",
    "                                            start_lr=Config.start_lr, final_lr=Config.final_lr)\n",
    "                                                \n",
    "pos_weight = torch.tensor(class_weights).to(device) if Config.use_class_weights else None\n",
    "if Config.loss == 'crossentropy':\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=Config.label_smoothing, weight=pos_weight)\n",
    "    accuracy = MulticlassAccuracy(num_classes=Config.n_classes).to(device)\n",
    "elif Config.loss == 'bce':\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight, weight=None)\n",
    "    accuracy = MultilabelAccuracy(num_labels=Config.n_classes).to(device)\n",
    "\n",
    "focal_criterion = FocalLoss(gamma=Config.focal_gamma, pos_weight=pos_weight)\n",
    "focal2way_criterion = BCEFocal2WayLoss(gamma=Config.focal_gamma, pos_weight=pos_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcvincent13\u001b[0m (\u001b[33m667\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/cedric/Documents/AI/Kaggle/BirdCLEF 2024/wandb/run-20240514_085002-1v6tz26l</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/667/birdclef-2024/runs/1v6tz26l' target=\"_blank\">2024-05-14_08-49-58_fold-0_dim-128x384_model-eca_nfnet_l0</a></strong> to <a href='https://wandb.ai/667/birdclef-2024' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/667/birdclef-2024' target=\"_blank\">https://wandb.ai/667/birdclef-2024</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/667/birdclef-2024/runs/1v6tz26l' target=\"_blank\">https://wandb.ai/667/birdclef-2024/runs/1v6tz26l</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 0.044:  29%|██▊       | 263/919 [04:51<08:04,  1.35it/s]wandb: Network error (ConnectionError), entering retry loop.\n",
      "train loss: 0.042: 100%|██████████| 919/919 [16:42<00:00,  1.09s/it]\n",
      "val loss: 0.015: 100%|██████████| 204/204 [01:27<00:00,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.064, Train Accuracy = 0.986, Train ROCAUC = 0.583,Train score = 0.583 | Val Loss = 0.036, Val Accuracy = 0.994, Val ROCAUC = 0.846, Val score = 0.846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 0.039: 100%|██████████| 919/919 [16:39<00:00,  1.09s/it]\n",
      "val loss: 0.015: 100%|██████████| 204/204 [01:25<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss = 0.037, Train Accuracy = 0.990, Train ROCAUC = 0.665,Train score = 0.665 | Val Loss = 0.033, Val Accuracy = 0.994, Val ROCAUC = 0.863, Val score = 0.863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 0.033: 100%|██████████| 919/919 [16:35<00:00,  1.08s/it]\n",
      "val loss: 0.023: 100%|██████████| 204/204 [01:25<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss = 0.037, Train Accuracy = 0.990, Train ROCAUC = 0.679,Train score = 0.679 | Val Loss = 0.035, Val Accuracy = 0.994, Val ROCAUC = 0.859, Val score = 0.859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 0.033: 100%|██████████| 919/919 [16:37<00:00,  1.09s/it]\n",
      "val loss: 0.017: 100%|██████████| 204/204 [01:26<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss = 0.036, Train Accuracy = 0.990, Train ROCAUC = 0.690,Train score = 0.690 | Val Loss = 0.032, Val Accuracy = 0.994, Val ROCAUC = 0.891, Val score = 0.891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 0.035: 100%|██████████| 919/919 [16:27<00:00,  1.07s/it]\n",
      "val loss: 0.011: 100%|██████████| 204/204 [01:26<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss = 0.036, Train Accuracy = 0.990, Train ROCAUC = 0.694,Train score = 0.694 | Val Loss = 0.032, Val Accuracy = 0.994, Val ROCAUC = 0.880, Val score = 0.880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 0.037: 100%|██████████| 919/919 [16:41<00:00,  1.09s/it]\n",
      "val loss: 0.012: 100%|██████████| 204/204 [01:27<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss = 0.035, Train Accuracy = 0.990, Train ROCAUC = 0.705,Train score = 0.705 | Val Loss = 0.030, Val Accuracy = 0.994, Val ROCAUC = 0.893, Val score = 0.893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 0.038: 100%|██████████| 919/919 [16:26<00:00,  1.07s/it]\n",
      "val loss: 0.015: 100%|██████████| 204/204 [01:25<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss = 0.034, Train Accuracy = 0.990, Train ROCAUC = 0.720,Train score = 0.720 | Val Loss = 0.029, Val Accuracy = 0.994, Val ROCAUC = 0.906, Val score = 0.906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 0.036:  94%|█████████▍| 867/919 [15:37<01:13,  1.42s/it]wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "train loss: 0.035: 100%|██████████| 919/919 [16:33<00:00,  1.08s/it]\n",
      "val loss: 0.010: 100%|██████████| 204/204 [01:25<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss = 0.033, Train Accuracy = 0.990, Train ROCAUC = 0.737,Train score = 0.737 | Val Loss = 0.028, Val Accuracy = 0.994, Val ROCAUC = 0.910, Val score = 0.910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 0.035: 100%|██████████| 919/919 [16:33<00:00,  1.08s/it]\n",
      "val loss: 0.011: 100%|██████████| 204/204 [01:25<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss = 0.033, Train Accuracy = 0.990, Train ROCAUC = 0.744,Train score = 0.744 | Val Loss = 0.027, Val Accuracy = 0.994, Val ROCAUC = 0.916, Val score = 0.916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 0.037: 100%|██████████| 919/919 [16:37<00:00,  1.09s/it]\n",
      "val loss: 0.008: 100%|██████████| 204/204 [01:25<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss = 0.032, Train Accuracy = 0.990, Train ROCAUC = 0.759,Train score = 0.759 | Val Loss = 0.026, Val Accuracy = 0.994, Val ROCAUC = 0.921, Val score = 0.921\n",
      "Done in 03h 01min 27s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train accuracy</td><td>▁█████████</td></tr><tr><td>train_auc</td><td>▁▄▅▅▅▆▆▇▇█</td></tr><tr><td>train_loss</td><td>█▂▂▂▂▂▂▁▁▁</td></tr><tr><td>train_score</td><td>▁▄▅▅▅▆▆▇▇█</td></tr><tr><td>val_accuracy</td><td>▁▂▁▂▃▄▃▆▅█</td></tr><tr><td>val_auc</td><td>▁▃▂▅▄▅▇▇██</td></tr><tr><td>val_loss</td><td>█▆▇▅▅▄▃▂▂▁</td></tr><tr><td>val_score</td><td>▁▃▂▅▄▅▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train accuracy</td><td>0.98993</td></tr><tr><td>train_auc</td><td>0.75945</td></tr><tr><td>train_loss</td><td>0.03177</td></tr><tr><td>train_score</td><td>0.75945</td></tr><tr><td>val_accuracy</td><td>0.99444</td></tr><tr><td>val_auc</td><td>0.92144</td></tr><tr><td>val_loss</td><td>0.02592</td></tr><tr><td>val_score</td><td>0.92144</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">2024-05-14_08-49-58_fold-0_dim-128x384_model-eca_nfnet_l0</strong> at: <a href='https://wandb.ai/667/birdclef-2024/runs/1v6tz26l' target=\"_blank\">https://wandb.ai/667/birdclef-2024/runs/1v6tz26l</a><br/> View project at: <a href='https://wandb.ai/667/birdclef-2024' target=\"_blank\">https://wandb.ai/667/birdclef-2024</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240514_085002-1v6tz26l/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "if Config.wandb:\n",
    "    run = wandb_init(fold, Config)\n",
    "\n",
    "save_dir = f\"{Config.base_dir}checkpoints/{Config.run_name}\"\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_metrics = {'AUC': [], 'Accuracy': [], 'Score': []}\n",
    "val_metrics = {'AUC': [], 'Accuracy': [], 'Score': []}\n",
    "\n",
    "for epoch in range(Config.num_epochs):\n",
    "    train_loss = 0\n",
    "    train_accuracy = 0\n",
    "    gt = []\n",
    "    preds = []\n",
    "    model.train()\n",
    "    train_iter = tqdm(train_loader)\n",
    "    for (batch, labels) in train_iter:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        batch = batch.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        out = model(batch, return_dict=Config.use_2wayfocal)\n",
    "        \n",
    "        if Config.use_focal:\n",
    "            loss = criterion(out, labels) + Config.focal_lambda * focal_criterion(out, labels)\n",
    "        elif Config.use_2wayfocal:\n",
    "            loss = criterion(out[\"logit\"], labels) + Config.focal_lambda * focal2way_criterion(out, labels)\n",
    "            out = out[\"logit\"]\n",
    "        else:\n",
    "            loss = criterion(out, labels)\n",
    "        loss.backward()\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=Config.max_grad_norm)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        train_iter.set_description(desc=f'train loss: {loss.item():.3f}')\n",
    "        train_loss += loss.item()\n",
    "        train_accuracy += accuracy(out, (labels>0).int())\n",
    "        if Config.loss == 'bce':\n",
    "            gt.append(((labels.detach().cpu().numpy())>0).astype(int))\n",
    "            preds.append(out.sigmoid().detach().cpu().numpy())\n",
    "        elif Config.loss == 'crossentropy':\n",
    "            gt.append(nn.functional.one_hot(labels.detach().cpu(), num_classes=Config.n_classes).numpy())\n",
    "            preds.append(nn.functional.softmax(out, dim=1).detach().cpu().numpy())\n",
    "\n",
    "    train_loss = train_loss / len(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracy = train_accuracy / len(train_loader)\n",
    "    train_metrics[\"Accuracy\"].append(train_accuracy)\n",
    "    gt = np.concatenate(gt)\n",
    "    preds = np.concatenate(preds)\n",
    "    train_auc = roc_auc(preds, gt)\n",
    "    train_score = score_np(preds, gt)\n",
    "    train_metrics[\"AUC\"].append(train_auc)\n",
    "    train_metrics[\"Score\"].append(train_score)\n",
    "\n",
    "\n",
    "    val_loss = 0\n",
    "    val_accuracy = 0\n",
    "    gt = []\n",
    "    preds = []\n",
    "    model.eval()\n",
    "    val_iter = tqdm(val_loader)\n",
    "    for (batch, labels) in val_iter:\n",
    "        batch = batch.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = model(batch, return_dict=Config.use_2wayfocal)\n",
    "            if Config.use_focal:\n",
    "                loss = criterion(out, labels) + Config.focal_lambda * focal_criterion(out, labels)\n",
    "            elif Config.use_2wayfocal:\n",
    "                loss = criterion(out[\"logit\"], labels) + Config.focal_lambda * focal2way_criterion(out, labels)\n",
    "                out = out[\"logit\"]\n",
    "            else:\n",
    "                loss = criterion(out, labels)\n",
    "\n",
    "        val_iter.set_description(desc=f'val loss: {loss.item():.3f}')\n",
    "        val_loss += loss.item()\n",
    "        val_accuracy += accuracy(out, (labels>0).int())\n",
    "        if Config.loss == 'bce':\n",
    "            gt.append(((labels.detach().cpu().numpy())>0).astype(int))\n",
    "            preds.append(out.sigmoid().detach().cpu().numpy())\n",
    "        elif Config.loss == 'crossentropy':\n",
    "            gt.append(nn.functional.one_hot(labels.detach().cpu(), num_classes=Config.n_classes).numpy())\n",
    "            preds.append(nn.functional.softmax(out, dim=1).detach().cpu().numpy())\n",
    "\n",
    "    val_loss = val_loss / len(val_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracy = val_accuracy / len(val_loader)\n",
    "    val_metrics['Accuracy'].append(val_accuracy)\n",
    "    gt = np.concatenate(gt)\n",
    "    preds = np.concatenate(preds)\n",
    "    val_auc = roc_auc(preds, gt)\n",
    "    val_score = score_np(preds, gt)\n",
    "    val_metrics['AUC'].append(val_auc)\n",
    "    val_metrics['Score'].append(val_score)\n",
    "\n",
    "    save_dict = {\n",
    "        \"model\": model.state_dict(),\n",
    "        \"optimizer\": optimizer.state_dict(),\n",
    "        \"scheduler\": scheduler.state_dict(),\n",
    "        \"epoch\": epoch+1,\n",
    "        \"train_losses\": train_losses,\n",
    "        \"train_metrics\": train_metrics,\n",
    "        \"val_losses\": val_losses,\n",
    "        \"val_metrics\": val_metrics\n",
    "    }\n",
    "\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.mkdir(save_dir)\n",
    "    torch.save(save_dict, save_dir + \"/checkpoint.pth\")\n",
    "    with open(save_dir + \"/logs.txt\", \"w\") as f:\n",
    "        f.write(f\"Epoch {epoch+1}: Train Loss = {train_loss:.3f} | Val Loss = {val_loss:.3f}\")\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"CONFIG:\")\n",
    "        for k,v in dict(vars(Config)).items():\n",
    "            if '__' not in k:\n",
    "                f.write(\"\\n\")\n",
    "                f.write(f\"{k}: {v}\")\n",
    "\n",
    "\n",
    "    if Config.wandb:\n",
    "        wandb.log({\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train accuracy\": train_accuracy,\n",
    "            \"train_auc\": train_auc,\n",
    "            \"train_score\": train_score,\n",
    "            \"val_loss\": val_loss,\n",
    "            \"val_accuracy\": val_accuracy,\n",
    "            \"val_auc\": val_auc,\n",
    "            \"val_score\": val_score,\n",
    "            \"lr\": scheduler.get_last_lr()\n",
    "        })\n",
    "\n",
    "\n",
    "    print(f'Epoch {epoch+1}: Train Loss = {train_loss:.3f}, Train Accuracy = {train_accuracy:.3f}, Train ROCAUC = {train_auc:.3f},\\\n",
    "Train score = {train_score:.3f} | Val Loss = {val_loss:.3f}, Val Accuracy = {val_accuracy:.3f}, \\\n",
    "Val ROCAUC = {val_auc:.3f}, Val score = {val_score:.3f}')\n",
    "\n",
    "\n",
    "def format_duration(seconds):\n",
    "    hours, remainder = divmod(seconds, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    return \"{:02}h {:02}min {:02}s\".format(int(hours), int(minutes), int(seconds))\n",
    "\n",
    "print(f'Done in {format_duration(time.time() - start_time)}')\n",
    "\n",
    "if Config.wandb:\n",
    "    #print('# WandB')\n",
    "    #log_wandb(valid_df)\n",
    "    wandb.run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nncf:NNCF initialized successfully. Supported frameworks detected: torch, onnx, openvino\n"
     ]
    }
   ],
   "source": [
    "import openvino as ov\n",
    "import nncf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load checkpoint\n",
    "device = torch.device('cpu')\n",
    "\n",
    "model = Config.Model(Config.n_classes, pretrained=False, model_name=Config.model_name).to(device)\n",
    "\n",
    "#save_dir = f\"{Config.base_dir}checkpoints/{Config.run_name}\"\n",
    "save_dir = 'checkpoints/2024-05-14_08-49-58_fold-0_dim-128x384_model-eca_nfnet_l0'\n",
    "checkpoint_name = f'{save_dir}/checkpoint.pth'\n",
    "checkpoint_ov = f'{save_dir}/checkpoint.xml'\n",
    "    \n",
    "checkpoint = torch.load(checkpoint_name, map_location='cpu')\n",
    "model.load_state_dict(checkpoint['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert and save model for openvino\n",
    "input_data = torch.rand(1, 3, Config.n_mels, Config.target_length)\n",
    "ov_model = ov.convert_model(model, example_input=input_data)\n",
    "ov.save_model(ov_model, save_dir + '/checkpoint.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and compile model with openvino\n",
    "core = ov.Core()\n",
    "ov_model = core.read_model(save_dir + \"/checkpoint.xml\")\n",
    "compiled_model = ov.compile_model(ov_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x770f57433e50>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quantize model to 8 bits openvino\n",
    "\n",
    "val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "birds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
