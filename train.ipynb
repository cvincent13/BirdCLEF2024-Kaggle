{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import wandb\n",
    "try:\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "    user_secrets = UserSecretsClient()\n",
    "    api_key = user_secrets.get_secret(\"WANDB\")\n",
    "    # Login to wandb with the API key\n",
    "    wandb.login(key=api_key)\n",
    "    # Set anonymous mode to None\n",
    "    anonymous = None\n",
    "except:\n",
    "    # If Kaggle secrets are not available, set anonymous mode to 'must'\n",
    "    anonymous = 'must'\n",
    "    # Login to wandb anonymously and relogin if needed\n",
    "    wandb.login(anonymous=anonymous, relogin=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cedric/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import IPython.display as ipd\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics.classification import MulticlassAccuracy, MultilabelAccuracy\n",
    "import audiomentations\n",
    "from torch.utils.data import default_collate\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "from src.audio_utils import play_audio, plot_specgram, plot_waveform\n",
    "from src.data import AudioDataset, FrequencyMaskingAug, TimeMaskingAug\n",
    "from src.data_utils import get_metadata, get_fold, get_metadata_from_csv\n",
    "from src.train_utils import FocalLoss, get_cosine_schedule_with_warmup, wandb_init\n",
    "from src.models import BasicClassifier\n",
    "from src.utils import score_np, roc_auc\n",
    "\n",
    "import ast\n",
    "import wandb\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    duration = 10\n",
    "    sample_rate = 32000\n",
    "    target_length = 384\n",
    "    n_mels = 128\n",
    "    n_fft = 2028\n",
    "    window = 2028\n",
    "    audio_len = duration*sample_rate\n",
    "    hop_length = audio_len // (target_length-1)\n",
    "    fmin = 20\n",
    "    fmax = 16000\n",
    "    top_db = 80\n",
    "\n",
    "    n_classes = 182\n",
    "    batch_size = 24\n",
    "    model_name = 'efficientnet_v2_s'\n",
    "    n_folds = 5\n",
    "    upsample_thr = 50\n",
    "    use_class_weights = False   # Test\n",
    "\n",
    "    standardize = False\n",
    "    dataset_mean = [-16.8828]\n",
    "    dataset_std = [12.4019]\n",
    "\n",
    "    data_aug = True     # Test     \n",
    "    cutmix_mixup = False     # Test\n",
    "    loss = 'bce'    # Test ('crossentropy', 'bce')\n",
    "    secondary_labels_weight = 0.3   # Test (0)\n",
    "    use_focal = False    # Test (only with bce)\n",
    "    focal_gamma = 2\n",
    "    focal_lambda = 1\n",
    "    label_smoothing = 0.05  # Only with crossentropy\n",
    "\n",
    "    num_epochs = 10\n",
    "    warmup_epochs = 0.5\n",
    "    lr = 1e-3\n",
    "    start_lr = 0.01 # relative to lr\n",
    "    final_lr = 0.01\n",
    "    weight_decay = 0.0001\n",
    "\n",
    "    wandb = True\n",
    "    competition   = 'birdclef-2024' \n",
    "    _wandb_kernel = 'cvincent13'\n",
    "    date = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    run_name = f\"{date}_fold-{0}_dim-{n_mels}x{target_length}_model-{model_name}\"\n",
    "    wandb_group = 'FirstTests'\n",
    "\n",
    "#metadata = get_metadata(Config.n_folds)\n",
    "metadata = get_metadata_from_csv('metadata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Train: 22045, 182 classes |Num Valid: 4892, 182 classes\n"
     ]
    }
   ],
   "source": [
    "fold = 0\n",
    "train_df, valid_df, class_weights = get_fold(metadata, fold, up_thr=Config.upsample_thr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data transforms and augmentations\n",
    "waveform_transforms = audiomentations.Compose([\n",
    "    audiomentations.Shift(min_shift=-0.5, max_shift=0.5, p=0.5),\n",
    "    audiomentations.SevenBandParametricEQ(min_gain_db=-12., max_gain_db=12., p=0.5),\n",
    "    audiomentations.AirAbsorption(min_temperature=10, max_temperature=20, min_humidity=30, max_humidity=90,\n",
    "                                  min_distance=10, max_distance=100, p=1.), \n",
    "\n",
    "    audiomentations.OneOf([\n",
    "        audiomentations.Gain(min_gain_db=-6., max_gain_db=6., p=1),  # How to handle waveforms out of [-1, 1] ? dont see the issue\n",
    "        audiomentations.GainTransition(min_gain_db=-12., max_gain_db=3., p=1)\n",
    "    ], p=1.),\n",
    "\n",
    "    audiomentations.OneOf([\n",
    "        audiomentations.AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=1.),\n",
    "        audiomentations.AddGaussianSNR(min_snr_db=5., max_snr_db=40., p=1.),\n",
    "        audiomentations.AddColorNoise(min_snr_db=5., max_snr_db=40., min_f_decay=-3.01, max_f_decay=-3.01, p=1.)\n",
    "    ], p=1.),\n",
    "\n",
    "    #audiomentations.AddShortNoises(sounds_path=unlabeled_dir, min_snr_db=3., max_snr_db=30., \n",
    "    #                           noise_rms='relative_to_whole_input',\n",
    "    #                           min_time_between_sounds=2., max_time_between_sounds=8., \n",
    "    #                           noise_transform=audiomentations.PolarityInversion(), p=0.5),\n",
    "    #audiomentations.AddBackgroundNoise(sounds_path=unlabeled_dir, min_snr_db=3., max_snr_db=30., \n",
    "    #                               noise_transform=audiomentations.PolarityInversion(), p=0.5),\n",
    "                                   \n",
    "    audiomentations.LowPassFilter(min_cutoff_freq=750., max_cutoff_freq=7500., min_rolloff=12, max_rolloff=24, p=0.8),\n",
    "    audiomentations.PitchShift(min_semitones=-2.5, max_semitones=2.5, p=0.3)\n",
    "])\n",
    "\n",
    "spec_transforms = nn.Sequential(\n",
    "    FrequencyMaskingAug(0.3, 0.1, Config.n_mels, n_masks=3, mask_mode='mean'),\n",
    "    TimeMaskingAug(0.3, 0.1, Config.target_length, n_masks=3, mask_mode='mean'),\n",
    ")\n",
    "\n",
    "\n",
    "waveform_transforms=None if not Config.data_aug else waveform_transforms\n",
    "spec_transforms=None if not Config.data_aug else spec_transforms\n",
    "\n",
    "\n",
    "train_dataset = AudioDataset(\n",
    "    train_df, \n",
    "    n_classes=Config.n_classes,\n",
    "    duration=Config.duration,\n",
    "    sample_rate=Config.sample_rate,\n",
    "    target_length=Config.target_length,\n",
    "    n_mels=Config.n_mels,\n",
    "    n_fft=Config.n_fft,\n",
    "    window=Config.window,\n",
    "    hop_length=Config.hop_length,\n",
    "    fmin=Config.fmin,\n",
    "    fmax=Config.fmax,\n",
    "    top_db=Config.top_db,\n",
    "    waveform_transforms=waveform_transforms,\n",
    "    spec_transforms=spec_transforms,\n",
    "    standardize=Config.standardize,\n",
    "    mean=Config.dataset_mean,\n",
    "    std=Config.dataset_std,\n",
    "    loss=Config.loss,\n",
    "    secondary_labels_weight=Config.secondary_labels_weight\n",
    "    )\n",
    "val_dataset = AudioDataset(\n",
    "    valid_df, \n",
    "    n_classes=Config.n_classes,\n",
    "    duration=Config.duration,\n",
    "    sample_rate=Config.sample_rate,\n",
    "    target_length=Config.target_length,\n",
    "    n_mels=Config.n_mels,\n",
    "    n_fft=Config.n_fft,\n",
    "    window=Config.window,\n",
    "    hop_length=Config.hop_length,\n",
    "    fmin=Config.fmin,\n",
    "    fmax=Config.fmax,\n",
    "    top_db=Config.top_db,\n",
    "    waveform_transforms=None,\n",
    "    spec_transforms=None,\n",
    "    standardize=Config.standardize,\n",
    "    mean=Config.dataset_mean,\n",
    "    std=Config.dataset_std,\n",
    "    loss=Config.loss,\n",
    "    secondary_labels_weight=Config.secondary_labels_weight\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutmix_or_mixup = v2.RandomApply([\n",
    "    v2.RandomChoice([\n",
    "        v2.CutMix(num_classes=Config.n_classes, alpha=0.5, one_hot_labels=Config.loss=='bce'),\n",
    "        v2.MixUp(num_classes=Config.n_classes, alpha=0.5, one_hot_labels=Config.loss=='bce')\n",
    "    ], p=[0.65, 0.35])\n",
    "], p=0.7)\n",
    "\n",
    "\n",
    "def mix_collate_fn(batch):\n",
    "    return cutmix_or_mixup(*default_collate(batch))\n",
    "\n",
    "collate_fn = mix_collate_fn if Config.cutmix_mixup else None\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=Config.batch_size, shuffle=True, num_workers=6, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=Config.batch_size, shuffle=False, num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "\n",
    "model = BasicClassifier(Config.n_classes, Config.model_name).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), weight_decay=Config.weight_decay, lr=Config.lr)\n",
    "spe = len(train_loader)\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=spe*Config.warmup_epochs, num_training_steps=spe*Config.num_epochs, \n",
    "                                            start_lr=Config.start_lr, final_lr=Config.final_lr)\n",
    "                                                \n",
    "pos_weight = torch.tensor(class_weights).to(device) if Config.use_class_weights else None\n",
    "if Config.loss == 'crossentropy':\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=Config.label_smoothing, weight=pos_weight)\n",
    "    accuracy = MulticlassAccuracy(num_classes=Config.n_classes).to(device)\n",
    "elif Config.loss == 'bce':\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight, weight=None)\n",
    "    accuracy = MultilabelAccuracy(num_labels=Config.n_classes).to(device)\n",
    "\n",
    "focal_criterion = FocalLoss(gamma=Config.focal_gamma, pos_weight=pos_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcvincent13\u001b[0m (\u001b[33m667\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/cedric/Documents/AI/Kaggle/BirdCLEF 2024/wandb/run-20240505_173157-c3f0kkp8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/667/birdclef-2024/runs/c3f0kkp8' target=\"_blank\">2024-05-05_17-31-54_fold-0_dim-128x384_model-efficientnet_v2_s</a></strong> to <a href='https://wandb.ai/667/birdclef-2024' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/667/birdclef-2024' target=\"_blank\">https://wandb.ai/667/birdclef-2024</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/667/birdclef-2024/runs/c3f0kkp8' target=\"_blank\">https://wandb.ai/667/birdclef-2024/runs/c3f0kkp8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 0.035:  49%|████▊     | 446/919 [06:38<03:40,  2.14it/s]wandb: Network error (ConnectionError), entering retry loop.\n",
      "train loss: 0.031: 100%|██████████| 919/919 [13:32<00:00,  1.13it/s]\n",
      "val loss: 0.036: 100%|██████████| 204/204 [01:05<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.066, Train Accuracy = 0.982, Train ROCAUC = 0.509,Train score = 0.509 | Val Loss = 0.038, Val Accuracy = 0.994, Val ROCAUC = 0.597, Val score = 0.597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 0.034: 100%|██████████| 919/919 [13:19<00:00,  1.15it/s]\n",
      "val loss: 0.032: 100%|██████████| 204/204 [01:04<00:00,  3.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss = 0.035, Train Accuracy = 0.994, Train ROCAUC = 0.520,Train score = 0.520 | Val Loss = 0.035, Val Accuracy = 0.994, Val ROCAUC = 0.556, Val score = 0.556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 0.034: 100%|██████████| 919/919 [13:16<00:00,  1.15it/s]\n",
      "val loss: 0.030: 100%|██████████| 204/204 [01:03<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss = 0.034, Train Accuracy = 0.994, Train ROCAUC = 0.497,Train score = 0.497 | Val Loss = 0.033, Val Accuracy = 0.994, Val ROCAUC = 0.571, Val score = 0.571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 0.034: 100%|██████████| 919/919 [13:16<00:00,  1.15it/s]\n",
      "val loss: 0.030: 100%|██████████| 204/204 [01:04<00:00,  3.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss = 0.034, Train Accuracy = 0.994, Train ROCAUC = 0.496,Train score = 0.496 | Val Loss = 0.033, Val Accuracy = 0.994, Val ROCAUC = 0.498, Val score = 0.498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 0.033: 100%|██████████| 919/919 [13:15<00:00,  1.15it/s]\n",
      "val loss: 0.030: 100%|██████████| 204/204 [01:04<00:00,  3.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss = 0.034, Train Accuracy = 0.994, Train ROCAUC = 0.493,Train score = 0.493 | Val Loss = 0.033, Val Accuracy = 0.994, Val ROCAUC = 0.586, Val score = 0.586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 0.033: 100%|██████████| 919/919 [13:15<00:00,  1.16it/s]\n",
      "val loss: 0.027: 100%|██████████| 204/204 [01:04<00:00,  3.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss = 0.034, Train Accuracy = 0.994, Train ROCAUC = 0.517,Train score = 0.517 | Val Loss = 0.032, Val Accuracy = 0.994, Val ROCAUC = 0.621, Val score = 0.621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 0.031: 100%|██████████| 919/919 [13:13<00:00,  1.16it/s]\n",
      "val loss: 0.027: 100%|██████████| 204/204 [01:03<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss = 0.033, Train Accuracy = 0.994, Train ROCAUC = 0.530,Train score = 0.530 | Val Loss = 0.032, Val Accuracy = 0.994, Val ROCAUC = 0.624, Val score = 0.624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 0.035: 100%|██████████| 919/919 [13:13<00:00,  1.16it/s]\n",
      "val loss: 0.025: 100%|██████████| 204/204 [01:04<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss = 0.033, Train Accuracy = 0.994, Train ROCAUC = 0.540,Train score = 0.540 | Val Loss = 0.032, Val Accuracy = 0.994, Val ROCAUC = 0.613, Val score = 0.613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 0.033: 100%|██████████| 919/919 [13:21<00:00,  1.15it/s]\n",
      "val loss: 0.026: 100%|██████████| 204/204 [01:03<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss = 0.033, Train Accuracy = 0.994, Train ROCAUC = 0.550,Train score = 0.550 | Val Loss = 0.032, Val Accuracy = 0.994, Val ROCAUC = 0.669, Val score = 0.669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/919 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     17\u001b[0m train_iter \u001b[38;5;241m=\u001b[39m tqdm(train_loader)\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (batch, labels) \u001b[38;5;129;01min\u001b[39;00m train_iter:\n\u001b[1;32m     19\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     21\u001b[0m     batch \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tqdm/std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1178\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1179\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1180\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/birds/lib/python3.10/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/birds/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1329\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1329\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/birds/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1295\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1292\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1295\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1296\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1297\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/envs/birds/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1133\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1133\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1135\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/birds/lib/python3.10/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[0;32m~/anaconda3/envs/birds/lib/python3.10/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/birds/lib/python3.10/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 424\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m~/anaconda3/envs/birds/lib/python3.10/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m    933\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "File \u001b[0;32m~/anaconda3/envs/birds/lib/python3.10/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "if Config.wandb:\n",
    "    run = wandb_init(fold, Config)\n",
    "\n",
    "save_dir = f\"checkpoints/{Config.run_name}\"\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_metrics = {'AUC': [], 'Accuracy': [], 'Score': []}\n",
    "val_metrics = {'AUC': [], 'Accuracy': [], 'Score': []}\n",
    "\n",
    "for epoch in range(Config.num_epochs):\n",
    "    train_loss = 0\n",
    "    train_accuracy = 0\n",
    "    gt = []\n",
    "    preds = []\n",
    "    model.train()\n",
    "    train_iter = tqdm(train_loader)\n",
    "    for (batch, labels) in train_iter:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        batch = batch.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        out = model(batch)\n",
    "        if Config.use_focal:\n",
    "            loss = criterion(out, labels) + Config.focal_lambda * focal_criterion(out, labels)\n",
    "        else:\n",
    "            loss = criterion(out, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        train_iter.set_description(desc=f'train loss: {loss.item():.3f}')\n",
    "        train_loss += loss.item()\n",
    "        train_accuracy += accuracy(out, (labels>0).int())\n",
    "        if Config.loss == 'bce':\n",
    "            gt.append(((labels.detach().cpu().numpy())>0).astype(int))\n",
    "            preds.append(out.sigmoid().detach().cpu().numpy())\n",
    "        elif Config.loss == 'crossentropy':\n",
    "            gt.append(nn.functional.one_hot(labels.detach().cpu(), num_classes=Config.n_classes).numpy())\n",
    "            preds.append(nn.functional.softmax(out, dim=1).detach().cpu().numpy())\n",
    "\n",
    "    train_loss = train_loss / len(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracy = train_accuracy / len(train_loader)\n",
    "    train_metrics[\"Accuracy\"].append(train_accuracy)\n",
    "    gt = np.concatenate(gt)\n",
    "    preds = np.concatenate(preds)\n",
    "    train_auc = roc_auc(preds, gt)\n",
    "    train_score = score_np(preds, gt)\n",
    "    train_metrics[\"AUC\"].append(train_auc)\n",
    "    train_metrics[\"Score\"].append(train_score)\n",
    "\n",
    "\n",
    "    val_loss = 0\n",
    "    val_accuracy = 0\n",
    "    gt = []\n",
    "    preds = []\n",
    "    model.eval()\n",
    "    val_iter = tqdm(val_loader)\n",
    "    for (batch, labels) in val_iter:\n",
    "        batch = batch.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = model(batch)\n",
    "            if Config.use_focal:\n",
    "                loss = criterion(out, labels) + Config.focal_lambda * focal_criterion(out, labels)\n",
    "            else:\n",
    "                loss = criterion(out, labels)\n",
    "\n",
    "        val_iter.set_description(desc=f'val loss: {loss.item():.3f}')\n",
    "        val_loss += loss.item()\n",
    "        val_accuracy += accuracy(out, (labels>0).int())\n",
    "        if Config.loss == 'bce':\n",
    "            gt.append(((labels.detach().cpu().numpy())>0).astype(int))\n",
    "            preds.append(out.sigmoid().detach().cpu().numpy())\n",
    "        elif Config.loss == 'crossentropy':\n",
    "            gt.append(nn.functional.one_hot(labels.detach().cpu(), num_classes=Config.n_classes).numpy())\n",
    "            preds.append(nn.functional.softmax(out, dim=1).detach().cpu().numpy())\n",
    "\n",
    "    val_loss = val_loss / len(val_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracy = val_accuracy / len(val_loader)\n",
    "    val_metrics['Accuracy'].append(val_accuracy)\n",
    "    gt = np.concatenate(gt)\n",
    "    preds = np.concatenate(preds)\n",
    "    val_auc = roc_auc(preds, gt)\n",
    "    val_score = score_np(preds, gt)\n",
    "    val_metrics['AUC'].append(val_auc)\n",
    "    val_metrics['Score'].append(val_score)\n",
    "\n",
    "    save_dict = {\n",
    "        \"model\": model.state_dict(),\n",
    "        \"optimizer\": optimizer.state_dict(),\n",
    "        \"scheduler\": scheduler.state_dict(),\n",
    "        \"epoch\": epoch+1,\n",
    "        \"train_losses\": train_losses,\n",
    "        \"train_metrics\": train_metrics,\n",
    "        \"val_losses\": val_losses,\n",
    "        \"val_metrics\": val_metrics\n",
    "    }\n",
    "\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.mkdir(save_dir)\n",
    "    torch.save(save_dict, save_dir + \"/checkpoint.pth\")\n",
    "    with open(save_dir + \"/logs.txt\", \"w\") as f:\n",
    "        f.write(f\"Epoch {epoch+1}: Train Loss = {train_loss:.3f} | Val Loss = {val_loss:.3f}\")\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"CONFIG:\")\n",
    "        for k,v in dict(vars(Config)).items():\n",
    "            if '__' not in k:\n",
    "                f.write(\"\\n\")\n",
    "                f.write(f\"{k}: {v}\")\n",
    "\n",
    "\n",
    "    if Config.wandb:\n",
    "        wandb.log({\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train accuracy\": train_accuracy,\n",
    "            \"train_auc\": train_auc,\n",
    "            \"train_score\": train_score,\n",
    "            \"val_loss\": val_loss,\n",
    "            \"val_accuracy\": val_accuracy,\n",
    "            \"val_auc\": val_auc,\n",
    "            \"val_score\": val_score,\n",
    "            \"lr\": scheduler.get_last_lr()\n",
    "        })\n",
    "\n",
    "\n",
    "    print(f'Epoch {epoch+1}: Train Loss = {train_loss:.3f}, Train Accuracy = {train_accuracy:.3f}, Train ROCAUC = {train_auc:.3f},\\\n",
    "Train score = {train_score:.3f} | Val Loss = {val_loss:.3f}, Val Accuracy = {val_accuracy:.3f}, \\\n",
    "Val ROCAUC = {val_auc:.3f}, Val score = {val_score:.3f}')\n",
    "\n",
    "\n",
    "def format_duration(seconds):\n",
    "    hours, remainder = divmod(seconds, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    return \"{:02}h {:02}min {:02}s\".format(int(hours), int(minutes), int(seconds))\n",
    "\n",
    "print(f'Done in {format_duration(time.time() - start_time)}')\n",
    "\n",
    "if Config.wandb:\n",
    "    #print('# WandB')\n",
    "    #log_wandb(valid_df)\n",
    "    wandb.run.finish()\n",
    "    display(ipd.IFrame(run.url, width=1080, height=720))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train accuracy</td><td>▁████████</td></tr><tr><td>train_auc</td><td>▃▄▂▁▁▄▆▇█</td></tr><tr><td>train_loss</td><td>█▁▁▁▁▁▁▁▁</td></tr><tr><td>train_score</td><td>▃▄▂▁▁▄▆▇█</td></tr><tr><td>val_accuracy</td><td>▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_auc</td><td>▅▃▄▁▅▆▆▆█</td></tr><tr><td>val_loss</td><td>█▅▂▂▂▁▁▁▁</td></tr><tr><td>val_score</td><td>▅▃▄▁▅▆▆▆█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train accuracy</td><td>0.9939</td></tr><tr><td>train_auc</td><td>0.55018</td></tr><tr><td>train_loss</td><td>0.0332</td></tr><tr><td>train_score</td><td>0.55018</td></tr><tr><td>val_accuracy</td><td>0.99397</td></tr><tr><td>val_auc</td><td>0.66944</td></tr><tr><td>val_loss</td><td>0.03185</td></tr><tr><td>val_score</td><td>0.66944</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">2024-05-05_17-31-54_fold-0_dim-128x384_model-efficientnet_v2_s</strong> at: <a href='https://wandb.ai/667/birdclef-2024/runs/c3f0kkp8' target=\"_blank\">https://wandb.ai/667/birdclef-2024/runs/c3f0kkp8</a><br/> View project at: <a href='https://wandb.ai/667/birdclef-2024' target=\"_blank\">https://wandb.ai/667/birdclef-2024</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240505_173157-c3f0kkp8/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1080\"\n",
       "            height=\"720\"\n",
       "            src=\"https://wandb.ai/667/birdclef-2024/runs/c3f0kkp8\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7eeb95d328c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.run.finish()\n",
    "display(ipd.IFrame(run.url, width=1080, height=720))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 182)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.functional.one_hot(labels.detach().cpu(), num_classes=182).numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 43,  13, 145, 152,  27, 137, 132,  62, 107, 109,  82,  17, 180],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22045, 182)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.4180e-06, 4.2658e-04, 5.8844e-05,  ..., 3.0927e-05, 7.2497e-06,\n",
       "         1.0027e-05],\n",
       "        [1.2548e-04, 3.9156e-04, 7.0476e-06,  ..., 2.0452e-05, 8.9177e-05,\n",
       "         5.7237e-04],\n",
       "        [4.5435e-03, 6.3721e-03, 4.4781e-03,  ..., 4.3707e-03, 9.0999e-04,\n",
       "         1.8922e-02],\n",
       "        ...,\n",
       "        [7.9350e-03, 5.7408e-04, 1.5541e-03,  ..., 1.1247e-03, 1.5814e-04,\n",
       "         1.6370e-02],\n",
       "        [5.3954e-03, 1.9911e-02, 3.6692e-04,  ..., 9.7607e-04, 6.4620e-03,\n",
       "         5.6922e-04],\n",
       "        [9.3946e-04, 5.5925e-03, 3.4661e-04,  ..., 2.3105e-04, 1.0715e-01,\n",
       "         1.1536e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.functional.softmax(out, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.36691537, 0.48500904, 0.4609493 , ..., 0.5471893 , 0.42748517,\n",
       "        0.5710229 ],\n",
       "       [0.52537864, 0.4471284 , 0.5180808 , ..., 0.47096235, 0.5777382 ,\n",
       "        0.41334236],\n",
       "       [0.47061932, 0.52697694, 0.55479383, ..., 0.61512756, 0.4984799 ,\n",
       "        0.484453  ],\n",
       "       ...,\n",
       "       [0.46711853, 0.0596365 , 0.14653054, ..., 0.11051289, 0.01716946,\n",
       "        0.64393234],\n",
       "       [0.39192435, 0.7040214 , 0.04199148, ..., 0.10442515, 0.43564963,\n",
       "        0.06366991],\n",
       "       [0.22335546, 0.6312654 , 0.09592591, ..., 0.06605653, 0.9704151 ,\n",
       "        0.03410903]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "birds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
