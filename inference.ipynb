{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cedric/miniconda3/envs/birds/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import time\n",
    "import scipy\n",
    "from functools import partial\n",
    "from scipy import signal\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "import torch.jit as jit\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import v2\n",
    "from torchvision.models import get_model\n",
    "import timm\n",
    "\n",
    "import openvino as ov\n",
    "import openvino.properties as props\n",
    "import openvino.properties.hint as hints\n",
    "from concurrent import futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    use_1_peak = True\n",
    "    peak_filter = 'none'\n",
    "    use_peaks = False\n",
    "    duration = 5\n",
    "    sample_rate = 32000\n",
    "    target_length = 500 #!!!!!!!!!!!!\n",
    "    n_mels = 128 #!!!!!!!!!!!!!!!\n",
    "    n_fft = 1024\n",
    "    window = 160 #!!!!!!!!!!!!!\n",
    "    audio_len = duration*sample_rate\n",
    "    hop_length = 64 #!!!!!!!!!!\n",
    "    fmin = 50\n",
    "    fmax = 16000\n",
    "    top_db = 80\n",
    "\n",
    "    n_classes = 182\n",
    "    n_channels = 1 #!!!!!!!!!!!\n",
    "    \n",
    "    use_openvino = True\n",
    "    multithreading = False\n",
    "    checkpoint_dir = 'checkpoints/2024-06-03_11-50-16_128x500_mn20_as_fold-2'\n",
    "    loss = 'crossentropy'\n",
    "    ensemble_checkpoints = ['checkpoints/2024-05-23_00-55-30_256x256_convnextv2_tiny.fcmae_ft_in22k_in1k_fold-0',\n",
    "                            'checkpoints/2024-05-23_00-55-30_256x256_convnextv2_tiny.fcmae_ft_in22k_in1k_fold-2',\n",
    "                            'checkpoints/2024-05-23_00-55-30_256x256_convnextv2_tiny.fcmae_ft_in22k_in1k_fold-3'\n",
    "                            ]\n",
    "    ensemble_losses = ['crossentropy', 'crossentropy', 'crossentropy']\n",
    "\n",
    "    standardize = False\n",
    "    dataset_mean = [-16.8828]\n",
    "    dataset_std = [12.4019]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_frames(waveform, duration=5, sr=32000):\n",
    "    frame_size = int(duration * sr)\n",
    "    surplus = waveform.size(-1)%frame_size\n",
    "    if surplus > 0:\n",
    "        waveform = waveform[:, :-surplus]\n",
    "    frames = waveform.view(-1, 1, frame_size)\n",
    "    return frames\n",
    "\n",
    "def find_peaks_max(x, filter='savgol'):\n",
    "    if filter == 'savgol':\n",
    "        smooth_x = signal.savgol_filter(x, window_length=100, polyorder=2)\n",
    "    elif filter == 'gaussian':\n",
    "        smooth_x = gaussian_filter1d(x, sigma=25)\n",
    "    else:\n",
    "        smooth_x = x\n",
    "    return smooth_x.argmax(axis=-1)\n",
    "\n",
    "def window_around_peak(len_x, peak, window_size):\n",
    "    half_window = window_size // 2\n",
    "    start_index = max(0, peak - half_window)\n",
    "    end_index = min(len_x, peak + half_window)\n",
    "\n",
    "    # Adjust the window if it's too close to the borders\n",
    "    if end_index - start_index < window_size:\n",
    "        if start_index == 0:\n",
    "            end_index = min(len_x, start_index + window_size)\n",
    "        elif end_index == len_x:\n",
    "            start_index = max(0, end_index - window_size)\n",
    "    return start_index, end_index\n",
    "\n",
    "class AudioDatasetInference(Dataset):\n",
    "    def __init__(\n",
    "            self, \n",
    "            files,\n",
    "            cfg,\n",
    "            targets = None\n",
    "            ):\n",
    "        super(AudioDatasetInference, self).__init__()\n",
    "        self.files = files\n",
    "        self.targets = targets\n",
    "        self.n_classes = cfg.n_classes\n",
    "        self.duration = cfg.duration\n",
    "        self.sample_rate = cfg.sample_rate\n",
    "        self.audio_len = self.duration*self.sample_rate\n",
    "        self.target_length = cfg.target_length\n",
    "        self.n_mels = cfg.n_mels\n",
    "        self.n_fft = cfg.n_fft\n",
    "        self.window = cfg.window\n",
    "        self.hop_length = cfg.hop_length\n",
    "        self.fmin = cfg.fmin\n",
    "        self.fmax = cfg.fmax\n",
    "        self.top_db = cfg.top_db\n",
    "        self.standardize = cfg.standardize\n",
    "        self.mean = cfg.dataset_mean\n",
    "        self.std = cfg.dataset_std\n",
    "        self.n_channels = cfg.n_channels\n",
    "        self.use_1_peak = cfg.use_1_peak\n",
    "        self.use_peaks = cfg.use_peaks\n",
    "        self.peak_filter = cfg.peak_filter\n",
    "\n",
    "        self.to_mel_spectrogramn = torchaudio.transforms.MelSpectrogram(self.sample_rate, n_fft=self.n_fft, win_length=self.window,  \n",
    "                                                 hop_length=self.hop_length, n_mels=self.n_mels, \n",
    "                                                 f_min=self.fmin, f_max=self.fmax)\n",
    "\n",
    "        self.mel_to_db = nn.Sequential(torchaudio.transforms.AmplitudeToDB(top_db=self.top_db))\n",
    "\n",
    "        if self.mean is not None and self.std is not None:\n",
    "            self.mel_to_db.append(v2.Normalize(mean=self.mean, std=self.std))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.targets is not None:\n",
    "            label = torch.tensor(self.targets[idx])\n",
    "\n",
    "        file = self.files[idx]\n",
    "        waveform, sr = torchaudio.load(file)\n",
    "        frames = create_frames(waveform)\n",
    "        spec = self.to_mel_spectrogramn(frames)\n",
    "\n",
    "        if self.use_1_peak:\n",
    "            per_frame_energy = spec.sum(dim=-2).squeeze().numpy()\n",
    "            peaks = find_peaks_max(per_frame_energy, filter=self.peak_filter)\n",
    "            new_spec = torch.empty((spec.size(0), self.n_channels, self.n_mels, self.target_length))\n",
    "            for p in range(len(peaks)):\n",
    "                start_index, end_index = window_around_peak(per_frame_energy.shape[-1], peaks[p], self.target_length)\n",
    "                new_spec[p] = spec[p,:,:,start_index:end_index]\n",
    "        \n",
    "        elif self.use_peaks:\n",
    "            per_frame_energy = spec.sum(dim=1).squeeze().numpy()\n",
    "            peak1 = find_peak_max(per_frame_energy, filter=self.peak_filter)\n",
    "            start_index, end_index = window_around_peak(len(per_frame_energy), peak, self.target_length)\n",
    "            spec1 = spec[:,:,start_index:end_index]\n",
    "\n",
    "        spec = self.mel_to_db(new_spec)\n",
    "\n",
    "        # Standardize\n",
    "        if self.standardize:\n",
    "            spec = (spec - spec.mean()) / spec.std()\n",
    "\n",
    "        # expand to 3 channels for imagenet trained models\n",
    "        spec = spec.expand(-1, self.n_channels,-1,-1)\n",
    "\n",
    "        if self.targets is not None:\n",
    "            return spec, label\n",
    "        else:\n",
    "            return spec, file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'data'\n",
    "train_dir = base_dir + '/train_audio/'\n",
    "test_dir = base_dir + '/test_soundscapes/'\n",
    "unlabeled_dir = base_dir + '/unlabeled_soundscapes/'\n",
    "\n",
    "class_names = sorted(os.listdir(train_dir))\n",
    "n_classes = len(class_names)\n",
    "class_labels = list(range(n_classes))\n",
    "label2name = dict(zip(class_labels, class_names))\n",
    "name2label = {v:k for k,v in label2name.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/unlabeled_soundscapes/646255149.ogg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/unlabeled_soundscapes/1171835482.ogg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/unlabeled_soundscapes/1590789246.ogg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/unlabeled_soundscapes/115033522.ogg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/unlabeled_soundscapes/1971688290.ogg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    filepath\n",
       "0   data/unlabeled_soundscapes/646255149.ogg\n",
       "1  data/unlabeled_soundscapes/1171835482.ogg\n",
       "2  data/unlabeled_soundscapes/1590789246.ogg\n",
       "3   data/unlabeled_soundscapes/115033522.ogg\n",
       "4  data/unlabeled_soundscapes/1971688290.ogg"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_paths = glob(base_dir + '/test_soundscapes/*ogg')\n",
    "if len(test_paths)==0:\n",
    "    test_paths = glob(base_dir + '/unlabeled_soundscapes/*ogg')[:10]\n",
    "test_df = pd.DataFrame(test_paths, columns=['filepath'])\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = AudioDatasetInference(\n",
    "    test_df['filepath'].values, \n",
    "    targets=None, \n",
    "    cfg=Config\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Config.multithreading:\n",
    "    def predict(specs, infer_request, final_activation):\n",
    "        sample_preds = np.empty(shape=(0, n_classes), dtype='float32')\n",
    "        start_time = time.time()\n",
    "        outs = infer_request.infer([specs])[0]\n",
    "        outs = final_activation(outs)\n",
    "        model_time = time.time()-start_time\n",
    "        sample_preds = np.concatenate([sample_preds, outs], axis=0)\n",
    "        return sample_preds, model_time\n",
    "\n",
    "    def helper(inputs):\n",
    "        return predict(inputs[0], inputs[1], inputs[2])\n",
    "\n",
    "    \n",
    "    def get_model(model_id):\n",
    "        core = ov.Core()\n",
    "        checkpoint_ov = Config.ensemble_checkpoints[model_id] + '/checkpoint.xml'\n",
    "        loss = Config.ensemble_losses[model_id]\n",
    "        config = {hints.performance_mode: hints.PerformanceMode.THROUGHPUT}\n",
    "        model = core.compile_model(checkpoint_ov, \"CPU\", config)\n",
    "        infer_request = model.create_infer_request()\n",
    "        return infer_request\n",
    "    \n",
    "    def get_final_activation(model_id):\n",
    "        loss = Config.ensemble_losses[model_id]\n",
    "        if loss == 'crossentropy':\n",
    "            final_activation = partial(scipy.special.softmax, axis=1)\n",
    "        elif loss == 'bce':\n",
    "            final_activation = scipy.special.expit\n",
    "        return final_activation\n",
    "        \n",
    "\n",
    "    start=time.time()\n",
    "\n",
    "    models = [get_model(model_id) for model_id in range(len(Config.ensemble_checkpoints))]\n",
    "    f_activations = [get_final_activation(model_id) for model_id in range(len(Config.ensemble_checkpoints))]\n",
    "    \n",
    "    preds = np.empty(shape=(0, n_classes), dtype='float32')\n",
    "    ids = []\n",
    "    ensemble_preds = np.empty(shape=(0, n_classes), dtype='float32')\n",
    "    for i in range(len(test_dataset)):\n",
    "        specs, file = test_dataset[i]\n",
    "        filename = file.split('/')[-1][:-4]\n",
    "        frame_ids = [f'{filename}_{(frame_id+1)*5}' for frame_id in range(len(specs))]\n",
    "        ids += frame_ids\n",
    "        \n",
    "        ensemble_preds = []\n",
    "        list_inputs = [(specs, models[k], f_activations[k]) for k in range(len(models))]\n",
    "        with futures.ThreadPoolExecutor(max_workers=len(Config.ensemble_checkpoints)) as executor:\n",
    "            for sample_preds, model_time in executor.map(helper, list_inputs):\n",
    "                ensemble_preds.append(sample_preds)\n",
    "                #print('model', model_time)\n",
    "        ensemble_preds = np.array(ensemble_preds)\n",
    "        #ensemble_preds = ensemble_preds.mean(axis=0)\n",
    "        ensemble_preds = (ensemble_preds**2).mean(axis=0) ** 0.5\n",
    "        preds = np.concatenate([preds, ensemble_preds], axis=0)\n",
    "\n",
    "    print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:19<00:00,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.404430866241455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if Config.use_openvino:\n",
    "    start=time.time()\n",
    "    \n",
    "    checkpoint_ov = Config.checkpoint_dir + '/checkpoint.xml'\n",
    "    config = {hints.performance_mode: hints.PerformanceMode.THROUGHPUT}\n",
    "    core = ov.Core()\n",
    "    model = core.compile_model(checkpoint_ov, \"AUTO\", config)\n",
    "\n",
    "\n",
    "    ids = []\n",
    "    preds = np.empty(shape=(0, n_classes), dtype='float32')\n",
    "    output_layer = model.output(0)\n",
    "    if Config.loss == 'crossentropy':\n",
    "        final_activation = partial(scipy.special.softmax, axis=1)\n",
    "    elif Config.loss == 'bce':\n",
    "        final_activation = scipy.special.expit\n",
    "\n",
    "    test_iter = tqdm(range(len(test_dataset)))\n",
    "    for i in test_iter:\n",
    "        #start_sample_time = time.time()\n",
    "        specs, file = test_dataset[i]\n",
    "        filename = file.split('/')[-1][:-4]\n",
    "        #data_time = time.time()\n",
    "        #print(\"data\", data_time-start_sample_time)\n",
    "        \n",
    "        outs = model([specs])[output_layer]\n",
    "        outs = final_activation(outs)\n",
    "        #model_time = time.time()\n",
    "        #print(\"model\", model_time-data_time)\n",
    "\n",
    "        frame_ids = [f'{filename}_{(frame_id+1)*5}' for frame_id in range(len(specs))]\n",
    "        ids += frame_ids\n",
    "\n",
    "        preds = np.concatenate([preds, outs], axis=0)\n",
    "        #end_time = time.time()\n",
    "        #print(\"end\", end_time-model_time)\n",
    "\n",
    "    print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not Config.use_openvino and not Config.multithreading:\n",
    "    device = torch.device('cpu')\n",
    "    checkpoint_name = Config.checkpoint_dir + '/checkpoint.pth'\n",
    "    model = src.models.BasicClassifier(Config.n_classes, pretrained=False, model_name=Config.model_name).to(device)\n",
    "    checkpoint = torch.load(checkpoint_name, map_location='cpu')\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    model = torch.jit.optimize_for_inference(torch.jit.script(model.eval()))\n",
    "\n",
    "    ids = []\n",
    "    preds = np.empty(shape=(0, n_classes), dtype='float32')\n",
    "\n",
    "    test_iter = tqdm(range(len(test_dataset)))\n",
    "    for i in test_iter:\n",
    "        specs, file = test_dataset[i]\n",
    "        filename = file.split('/')[-1][:-4]\n",
    "        specs = specs.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outs = model(specs)\n",
    "            if Config.loss == 'crossentropy':\n",
    "                outs = nn.functional.softmax(outs, dim=1).detach().cpu().numpy()\n",
    "            elif Config.loss == 'bce':\n",
    "                outs = outs.sigmoid().detach().cpu().numpy()\n",
    "\n",
    "        frame_ids = [f'{filename}_{(frame_id+1)*5}' for frame_id in range(len(specs))]\n",
    "        ids += frame_ids\n",
    "\n",
    "        preds = np.concatenate([preds, outs], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>asbfly</th>\n",
       "      <th>ashdro1</th>\n",
       "      <th>ashpri1</th>\n",
       "      <th>ashwoo2</th>\n",
       "      <th>asikoe2</th>\n",
       "      <th>asiope1</th>\n",
       "      <th>aspfly1</th>\n",
       "      <th>aspswi1</th>\n",
       "      <th>barfly1</th>\n",
       "      <th>...</th>\n",
       "      <th>whbwoo2</th>\n",
       "      <th>whcbar1</th>\n",
       "      <th>whiter2</th>\n",
       "      <th>whrmun</th>\n",
       "      <th>whtkin2</th>\n",
       "      <th>woosan</th>\n",
       "      <th>wynlau1</th>\n",
       "      <th>yebbab1</th>\n",
       "      <th>yebbul3</th>\n",
       "      <th>zitcis1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XC756601_5</td>\n",
       "      <td>0.005847</td>\n",
       "      <td>0.011639</td>\n",
       "      <td>0.002512</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.019070</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000609</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000811</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>0.001206</td>\n",
       "      <td>0.000926</td>\n",
       "      <td>0.005042</td>\n",
       "      <td>0.010253</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.004853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XC756601_10</td>\n",
       "      <td>0.008243</td>\n",
       "      <td>0.007165</td>\n",
       "      <td>0.001763</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.018658</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000512</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000528</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.002916</td>\n",
       "      <td>0.001131</td>\n",
       "      <td>0.004920</td>\n",
       "      <td>0.010568</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.005552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XC756601_15</td>\n",
       "      <td>0.010177</td>\n",
       "      <td>0.009778</td>\n",
       "      <td>0.003066</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.017798</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.001104</td>\n",
       "      <td>0.007026</td>\n",
       "      <td>0.008240</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.006269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XC756601_20</td>\n",
       "      <td>0.006208</td>\n",
       "      <td>0.006755</td>\n",
       "      <td>0.002717</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.014288</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000561</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000782</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.001888</td>\n",
       "      <td>0.001559</td>\n",
       "      <td>0.007132</td>\n",
       "      <td>0.009607</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.012148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XC756601_25</td>\n",
       "      <td>0.006516</td>\n",
       "      <td>0.006837</td>\n",
       "      <td>0.001713</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.020643</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000877</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>0.001813</td>\n",
       "      <td>0.001479</td>\n",
       "      <td>0.005192</td>\n",
       "      <td>0.010191</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.007364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 183 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        row_id    asbfly   ashdro1   ashpri1   ashwoo2   asikoe2   asiope1  \\\n",
       "0   XC756601_5  0.005847  0.011639  0.002512  0.000110  0.019070  0.000015   \n",
       "1  XC756601_10  0.008243  0.007165  0.001763  0.000092  0.018658  0.000011   \n",
       "2  XC756601_15  0.010177  0.009778  0.003066  0.000166  0.017798  0.000020   \n",
       "3  XC756601_20  0.006208  0.006755  0.002717  0.000150  0.014288  0.000024   \n",
       "4  XC756601_25  0.006516  0.006837  0.001713  0.000164  0.020643  0.000016   \n",
       "\n",
       "    aspfly1   aspswi1   barfly1  ...   whbwoo2   whcbar1   whiter2    whrmun  \\\n",
       "0  0.000609  0.000143  0.000069  ...  0.000811  0.000281  0.001206  0.000926   \n",
       "1  0.000512  0.000136  0.000104  ...  0.000528  0.000333  0.002916  0.001131   \n",
       "2  0.000657  0.000119  0.000143  ...  0.000895  0.000277  0.001253  0.001104   \n",
       "3  0.000561  0.000175  0.000171  ...  0.000782  0.000253  0.001888  0.001559   \n",
       "4  0.000494  0.000309  0.000087  ...  0.000877  0.000263  0.001813  0.001479   \n",
       "\n",
       "    whtkin2    woosan   wynlau1   yebbab1   yebbul3   zitcis1  \n",
       "0  0.005042  0.010253  0.000052  0.000306  0.000032  0.004853  \n",
       "1  0.004920  0.010568  0.000061  0.000224  0.000028  0.005552  \n",
       "2  0.007026  0.008240  0.000074  0.000242  0.000039  0.006269  \n",
       "3  0.007132  0.009607  0.000056  0.000403  0.000023  0.012148  \n",
       "4  0.005192  0.010191  0.000060  0.000307  0.000018  0.007364  \n",
       "\n",
       "[5 rows x 183 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Submit prediction\n",
    "pred_df = pd.DataFrame(ids, columns=['row_id'])\n",
    "pred_df.loc[:, class_names] = preds\n",
    "pred_df.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "birds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
