{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cedric/miniconda3/envs/birds/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import time\n",
    "import scipy\n",
    "from functools import partial\n",
    "\n",
    "import torch.jit as jit\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import v2\n",
    "from torchvision.models import get_model\n",
    "import timm\n",
    "\n",
    "import openvino as ov\n",
    "import openvino.properties as props\n",
    "import openvino.properties.hint as hints\n",
    "from concurrent import futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    duration = 5\n",
    "    sample_rate = 32000\n",
    "    target_length = 500\n",
    "    n_mels = 128\n",
    "    n_fft = 1024\n",
    "    window = 800\n",
    "    audio_len = duration*sample_rate\n",
    "    hop_length = audio_len // (target_length-1)\n",
    "    fmin = 20\n",
    "    fmax = 16000\n",
    "    top_db = 80\n",
    "\n",
    "    n_classes = 182\n",
    "    n_channels = 1\n",
    "\n",
    "    use_openvino = True\n",
    "    multithreading = False\n",
    "    checkpoint_dir = 'checkpoints/2024-05-29_08-53-40_128x500_mn20_as_fold-2'\n",
    "    loss = 'crossentropy'\n",
    "    ensemble_checkpoints = ['checkpoints/2024-05-23_00-55-30_256x256_convnextv2_tiny.fcmae_ft_in22k_in1k_fold-0',\n",
    "                            'checkpoints/2024-05-23_00-55-30_256x256_convnextv2_tiny.fcmae_ft_in22k_in1k_fold-2',\n",
    "                            'checkpoints/2024-05-23_00-55-30_256x256_convnextv2_tiny.fcmae_ft_in22k_in1k_fold-3'\n",
    "                            ]\n",
    "    ensemble_losses = ['crossentropy', 'crossentropy', 'crossentropy']\n",
    "\n",
    "    standardize = False\n",
    "    dataset_mean = [-16.8828]\n",
    "    dataset_std = [12.4019]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_frames(waveform, duration=5, sr=32000):\n",
    "    frame_size = int(duration * sr)\n",
    "    surplus = waveform.size(-1)%frame_size\n",
    "    if surplus > 0:\n",
    "        waveform = waveform[:, :-surplus]\n",
    "    frames = waveform.view(-1, 1, frame_size)\n",
    "    return frames\n",
    "\n",
    "class AudioDatasetInference(Dataset):\n",
    "    def __init__(\n",
    "            self, \n",
    "            files,\n",
    "            targets = None, \n",
    "            n_classes = 182,\n",
    "            duration = 5,\n",
    "            sample_rate = 32000,\n",
    "            target_length = 384,\n",
    "            n_mels = 128,\n",
    "            n_fft = 2028,\n",
    "            window = 2028,\n",
    "            hop_length = None,\n",
    "            fmin = 20,\n",
    "            fmax = 16000,\n",
    "            top_db = 80,\n",
    "            standardize=True,\n",
    "            mean=None,\n",
    "            std=None\n",
    "            ):\n",
    "        super(AudioDatasetInference, self).__init__()\n",
    "        self.files = files\n",
    "        self.targets = targets\n",
    "        self.n_classes = n_classes\n",
    "        self.duration = duration\n",
    "        self.sample_rate = sample_rate\n",
    "        self.audio_len = duration*sample_rate\n",
    "        self.target_length = target_length\n",
    "        self.n_mels = n_mels\n",
    "        self.n_fft = n_fft\n",
    "        self.window = window\n",
    "        self.hop_length = self.audio_len // (target_length-1) if not hop_length else hop_length\n",
    "        self.fmin = fmin\n",
    "        self.fmax = fmax\n",
    "        self.top_db = top_db\n",
    "        self.standardize = standardize\n",
    "\n",
    "        self.to_mel_spectrogramn = nn.Sequential(\n",
    "            torchaudio.transforms.MelSpectrogram(self.sample_rate, n_fft=self.n_fft, win_length=self.window,  \n",
    "                                                 hop_length=self.hop_length, n_mels=self.n_mels, \n",
    "                                                 f_min=self.fmin, f_max=self.fmax),\n",
    "            torchaudio.transforms.AmplitudeToDB(top_db=self.top_db)\n",
    "        )\n",
    "        if mean is not None and std is not None:\n",
    "            self.to_mel_spectrogramn.append(v2.Normalize(mean=mean, std=std))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        file = self.files[idx]\n",
    "        waveform, sr = torchaudio.load(file)\n",
    "        frames = create_frames(waveform)\n",
    "        spec = self.to_mel_spectrogramn(frames)\n",
    "        # Standardize\n",
    "        if self.standardize:\n",
    "            spec = (spec - spec.mean()) / spec.std()\n",
    "\n",
    "        # expand to 3 channels for imagenet trained models\n",
    "        spec = spec.expand(-1,Config.n_channels,-1,-1)\n",
    "\n",
    "        if self.targets is not None:\n",
    "            label = torch.tensor(self.targets[idx])\n",
    "            return spec, label\n",
    "        else:\n",
    "            return spec, file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'data'\n",
    "train_dir = base_dir + '/train_audio/'\n",
    "test_dir = base_dir + '/test_soundscapes/'\n",
    "unlabeled_dir = base_dir + '/unlabeled_soundscapes/'\n",
    "\n",
    "class_names = sorted(os.listdir(train_dir))\n",
    "n_classes = len(class_names)\n",
    "class_labels = list(range(n_classes))\n",
    "label2name = dict(zip(class_labels, class_names))\n",
    "name2label = {v:k for k,v in label2name.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/unlabeled_soundscapes/646255149.ogg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/unlabeled_soundscapes/1171835482.ogg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/unlabeled_soundscapes/1590789246.ogg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/unlabeled_soundscapes/115033522.ogg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/unlabeled_soundscapes/1971688290.ogg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    filepath\n",
       "0   data/unlabeled_soundscapes/646255149.ogg\n",
       "1  data/unlabeled_soundscapes/1171835482.ogg\n",
       "2  data/unlabeled_soundscapes/1590789246.ogg\n",
       "3   data/unlabeled_soundscapes/115033522.ogg\n",
       "4  data/unlabeled_soundscapes/1971688290.ogg"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_paths = glob(base_dir + '/test_soundscapes/*ogg')\n",
    "if len(test_paths)==0:\n",
    "    test_paths = glob(base_dir + '/unlabeled_soundscapes/*ogg')[:10]\n",
    "test_df = pd.DataFrame(test_paths, columns=['filepath'])\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = AudioDatasetInference(\n",
    "    test_df['filepath'].values, \n",
    "    targets=None, \n",
    "    n_classes=Config.n_classes,\n",
    "    duration=5,\n",
    "    sample_rate=Config.sample_rate,\n",
    "    target_length=Config.target_length,\n",
    "    n_mels=Config.n_mels,\n",
    "    n_fft=Config.n_fft,\n",
    "    window=Config.window,\n",
    "    hop_length=Config.hop_length,\n",
    "    fmin=Config.fmin,\n",
    "    fmax=Config.fmax,\n",
    "    top_db=Config.top_db,\n",
    "    standardize=Config.standardize,\n",
    "    mean=Config.dataset_mean,\n",
    "    std=Config.dataset_std\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Config.multithreading:\n",
    "    def predict(dataset, model, loss):\n",
    "        ids = []\n",
    "        preds = np.empty(shape=(0, n_classes), dtype='float32')\n",
    "        #output_layer = model.output(0)\n",
    "        infer_request = model.create_infer_request()\n",
    "        if loss == 'crossentropy':\n",
    "            final_activation = partial(scipy.special.softmax, axis=1)\n",
    "        elif loss == 'bce':\n",
    "            final_activation = scipy.special.expit\n",
    "\n",
    "        specs, file = dataset[0]\n",
    "        for i in range(1, len(dataset)):\n",
    "            infer_request.start_async([specs])\n",
    "            specs, file = dataset[i]\n",
    "            filename = file.split('/')[-1][:-4]\n",
    "\n",
    "            #outs = model([specs])[output_layer]\n",
    "            infer_request.wait()\n",
    "            outs = infer_request.get_output_tensor(0).data\n",
    "            outs = final_activation(outs)\n",
    "\n",
    "            frame_ids = [f'{filename}_{(frame_id+1)*5}' for frame_id in range(len(specs))]\n",
    "            ids += frame_ids\n",
    "\n",
    "            preds = np.concatenate([preds, outs], axis=0)\n",
    "\n",
    "        return preds, ids\n",
    "\n",
    "    def run_prediction(data_loader, model_id):\n",
    "        core = ov.Core()\n",
    "        checkpoint_ov = Config.ensemble_checkpoints[model_id] + '/checkpoint.xml'\n",
    "        loss = Config.ensemble_losses[model_id]\n",
    "        config = {hints.performance_mode: hints.PerformanceMode.THROUGHPUT}\n",
    "        model = core.compile_model(checkpoint_ov, \"CPU\", config)\n",
    "        \n",
    "        preds, ids = predict(data_loader, model, loss)\n",
    "        del core, model, loss\n",
    "        gc.collect()\n",
    "        \n",
    "        print(f\"Done model {model_id}\")\n",
    "        return preds, ids\n",
    "\n",
    "    def helper(inputs):\n",
    "        return run_prediction(inputs[0], inputs[1])\n",
    "\n",
    "\n",
    "    start=time.time()\n",
    "    \n",
    "    audios = [(test_dataset, model_id) for model_id in range(len(Config.ensemble_checkpoints))]\n",
    "    ensemble_preds = []\n",
    "    with futures.ThreadPoolExecutor(max_workers=len(Config.ensemble_checkpoints)) as executor:\n",
    "        for preds, ids in executor.map(helper, audios):\n",
    "            ensemble_preds.append(preds)\n",
    "    ensemble_preds = np.array(ensemble_preds)\n",
    "    ensemble_preds = np.mean(ensemble_preds, axis=0)\n",
    "    #ensemble_preds = (ensemble_preds**2).mean(axis=0) ** 0.5\n",
    "\n",
    "    print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:17<00:00,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.917014598846436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if Config.use_openvino:\n",
    "    start=time.time()\n",
    "    \n",
    "    checkpoint_ov = Config.checkpoint_dir + '/checkpoint.xml'\n",
    "    config = {hints.performance_mode: hints.PerformanceMode.THROUGHPUT}\n",
    "    core = ov.Core()\n",
    "    model = core.compile_model(checkpoint_ov, \"CPU\", config)\n",
    "    #infer_request = model.create_infer_request()\n",
    "    output_layer = model.output(0)\n",
    "\n",
    "    ids = []\n",
    "    preds = np.empty(shape=(0, n_classes), dtype='float32')\n",
    "    if Config.loss == 'crossentropy':\n",
    "        final_activation = partial(scipy.special.softmax, axis=1)\n",
    "    elif Config.loss == 'bce':\n",
    "        final_activation = scipy.special.expit\n",
    "\n",
    "    test_iter = tqdm(range(len(test_dataset)))\n",
    "    for i in test_iter:\n",
    "        specs, file = test_dataset[i]\n",
    "        filename = file.split('/')[-1][:-4]\n",
    "\n",
    "        outs = model([specs])[output_layer]\n",
    "        #outs = infer_request.infer([specs])[0]\n",
    "        outs = final_activation(outs)\n",
    "\n",
    "        frame_ids = [f'{filename}_{(frame_id+1)*5}' for frame_id in range(len(specs))]\n",
    "        ids += frame_ids\n",
    "\n",
    "        preds = np.concatenate([preds, outs], axis=0)\n",
    "\n",
    "    print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [03:01<00:00, 18.11s/it]\n"
     ]
    }
   ],
   "source": [
    "if not Config.use_openvino and not Config.multithreading:\n",
    "    device = torch.device('cpu')\n",
    "    checkpoint_name = Config.checkpoint_dir + '/checkpoint.pth'\n",
    "    model = src.models.BasicClassifier(Config.n_classes, pretrained=False, model_name=Config.model_name).to(device)\n",
    "    checkpoint = torch.load(checkpoint_name, map_location='cpu')\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    model = torch.jit.optimize_for_inference(torch.jit.script(model.eval()))\n",
    "\n",
    "    ids = []\n",
    "    preds = np.empty(shape=(0, n_classes), dtype='float32')\n",
    "\n",
    "    test_iter = tqdm(range(len(test_dataset)))\n",
    "    for i in test_iter:\n",
    "        specs, file = test_dataset[i]\n",
    "        filename = file.split('/')[-1][:-4]\n",
    "        specs = specs.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outs = model(specs)\n",
    "            if Config.loss == 'crossentropy':\n",
    "                outs = nn.functional.softmax(outs, dim=1).detach().cpu().numpy()\n",
    "            elif Config.loss == 'bce':\n",
    "                outs = outs.sigmoid().detach().cpu().numpy()\n",
    "\n",
    "        frame_ids = [f'{filename}_{(frame_id+1)*5}' for frame_id in range(len(specs))]\n",
    "        ids += frame_ids\n",
    "\n",
    "        preds = np.concatenate([preds, outs], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>asbfly</th>\n",
       "      <th>ashdro1</th>\n",
       "      <th>ashpri1</th>\n",
       "      <th>ashwoo2</th>\n",
       "      <th>asikoe2</th>\n",
       "      <th>asiope1</th>\n",
       "      <th>aspfly1</th>\n",
       "      <th>aspswi1</th>\n",
       "      <th>barfly1</th>\n",
       "      <th>...</th>\n",
       "      <th>whbwoo2</th>\n",
       "      <th>whcbar1</th>\n",
       "      <th>whiter2</th>\n",
       "      <th>whrmun</th>\n",
       "      <th>whtkin2</th>\n",
       "      <th>woosan</th>\n",
       "      <th>wynlau1</th>\n",
       "      <th>yebbab1</th>\n",
       "      <th>yebbul3</th>\n",
       "      <th>zitcis1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XC756601_5</td>\n",
       "      <td>0.005847</td>\n",
       "      <td>0.011639</td>\n",
       "      <td>0.002512</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.019070</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000609</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000811</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>0.001206</td>\n",
       "      <td>0.000926</td>\n",
       "      <td>0.005042</td>\n",
       "      <td>0.010253</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.004853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XC756601_10</td>\n",
       "      <td>0.008243</td>\n",
       "      <td>0.007165</td>\n",
       "      <td>0.001763</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.018658</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000512</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000528</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.002916</td>\n",
       "      <td>0.001131</td>\n",
       "      <td>0.004920</td>\n",
       "      <td>0.010568</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.005552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XC756601_15</td>\n",
       "      <td>0.010177</td>\n",
       "      <td>0.009778</td>\n",
       "      <td>0.003066</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.017798</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.001104</td>\n",
       "      <td>0.007026</td>\n",
       "      <td>0.008240</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.006269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XC756601_20</td>\n",
       "      <td>0.006208</td>\n",
       "      <td>0.006755</td>\n",
       "      <td>0.002717</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.014288</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000561</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000782</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.001888</td>\n",
       "      <td>0.001559</td>\n",
       "      <td>0.007132</td>\n",
       "      <td>0.009607</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.012148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XC756601_25</td>\n",
       "      <td>0.006516</td>\n",
       "      <td>0.006837</td>\n",
       "      <td>0.001713</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.020643</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000877</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>0.001813</td>\n",
       "      <td>0.001479</td>\n",
       "      <td>0.005192</td>\n",
       "      <td>0.010191</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.007364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 183 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        row_id    asbfly   ashdro1   ashpri1   ashwoo2   asikoe2   asiope1  \\\n",
       "0   XC756601_5  0.005847  0.011639  0.002512  0.000110  0.019070  0.000015   \n",
       "1  XC756601_10  0.008243  0.007165  0.001763  0.000092  0.018658  0.000011   \n",
       "2  XC756601_15  0.010177  0.009778  0.003066  0.000166  0.017798  0.000020   \n",
       "3  XC756601_20  0.006208  0.006755  0.002717  0.000150  0.014288  0.000024   \n",
       "4  XC756601_25  0.006516  0.006837  0.001713  0.000164  0.020643  0.000016   \n",
       "\n",
       "    aspfly1   aspswi1   barfly1  ...   whbwoo2   whcbar1   whiter2    whrmun  \\\n",
       "0  0.000609  0.000143  0.000069  ...  0.000811  0.000281  0.001206  0.000926   \n",
       "1  0.000512  0.000136  0.000104  ...  0.000528  0.000333  0.002916  0.001131   \n",
       "2  0.000657  0.000119  0.000143  ...  0.000895  0.000277  0.001253  0.001104   \n",
       "3  0.000561  0.000175  0.000171  ...  0.000782  0.000253  0.001888  0.001559   \n",
       "4  0.000494  0.000309  0.000087  ...  0.000877  0.000263  0.001813  0.001479   \n",
       "\n",
       "    whtkin2    woosan   wynlau1   yebbab1   yebbul3   zitcis1  \n",
       "0  0.005042  0.010253  0.000052  0.000306  0.000032  0.004853  \n",
       "1  0.004920  0.010568  0.000061  0.000224  0.000028  0.005552  \n",
       "2  0.007026  0.008240  0.000074  0.000242  0.000039  0.006269  \n",
       "3  0.007132  0.009607  0.000056  0.000403  0.000023  0.012148  \n",
       "4  0.005192  0.010191  0.000060  0.000307  0.000018  0.007364  \n",
       "\n",
       "[5 rows x 183 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Submit prediction\n",
    "pred_df = pd.DataFrame(ids, columns=['row_id'])\n",
    "pred_df.loc[:, class_names] = preds\n",
    "pred_df.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "birds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
